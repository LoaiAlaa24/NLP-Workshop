# NLP Workshop

This repository contains the materials for the NLP workshop conducted by Loay Nasser. The workshop focuses on various transformer-based models used in Natural Language Processing (NLP), including BERT, GPT, and T5.

## Workshop Topics

The workshop includes Jupyter notebooks covering the following topics:

1. Introduction to BERT
2. BERT Model in Depth
3. GPT: Generative Pre-trained Transformer
4. T5: Text-To-Text Transfer Transformer

## Reference Papers / Courses

The following reference papers are recommended for further reading:

1. Introduction to Transformer Models for NLP: Using BERT, GPT, and More to Solve Modern Natural Language Processing Tasks, O'Reilly, Sinan Ozdemir.
2. Advanced NLP course, Technical University of Munich, Prof Dr. Georg Groh.
3. Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017). Attention Is All You Need. In Proceedings of the 31st Conference on Neural Information Processing Systems (NeurIPS 2017), Long Beach, CA, USA.

Feel free to explore the notebooks and dive into the fascinating world of transformer models in NLP!

For any inquiries or feedback, please contact Loay Nasser at [Nasser.Loay@swm.de].
